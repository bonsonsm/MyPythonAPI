import re
import csv
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet

 
replacement_patterns = [
    ("won't", "will not"),
    ("can't", "cannot"),
    ("i'm", "i am"),
    ("ain't", "is not"),
    ("(\w+)'ll", "\g<1> will"),
    ("(\w+)n't", "\g<1> not"),
    ("(\w+)'ve", "\g<1> have"),
    ("(\w+)'s", "\g<1> is"),
    ("(\w+)'re", "\g<1> are'"),
    ("(\w+)'d", "\g<1> would")
]

class RegexpReplacer(object):
    def __init__(self, patterns=replacement_patterns):
        # Word expansion replacement patterns
        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]
        # For repeating characters within a word
        self.repeat_regexp = re.compile(r'(\w*)(\w)\2(\w*)')
        self.repl = r'\1\2\3'
        # Word replacement Map
        self.word_map = {}
        

    '''
    Expand words that are shortened in the English Language
    E.G. Can't, Shouldn't
    '''
    def expand(self, text):
        for (pattern, repl) in self.patterns:
            text = re.sub(pattern, repl, text)
        return text

    '''
    Expand the words athat are shortened in the English Language
    E.G. Can't, Shouldn't
    Then break and tokenize them
    E.G. Can't = Cannot = Can Not
    '''
    def expandAndTokenize(self, text):
        for (pattern, repl) in self.patterns:
            text = re.sub(pattern, repl, text)
        text = word_tokenize(text)
        return text

    '''
    Removes repating characters from any word that is given as input
    Checks in parallel if the word exists
    '''
    def removeRepeats(self, word):
        # remove repeating characters only if the word does not exist
        if wordnet.synsets(word):
            return word
        repl_word = self.repeat_regexp.sub(self.repl, word)
        if repl_word != word:
            return self.removeRepeats(repl_word)
        else:
            return repl_word

    '''
    Create a words dictionary t use for word replacement
    '''
    def createWordMap(self, words):
        self.word_map = words

    '''
    Create a word map from csv
    '''
    def createWordMapFromCSV(self, words):
        for line in csv.reader(open(fname)):
            word, syn = line
            word_map[word] = syn
        self.word_map = word_map
        
    '''
    Get the words from the created dictionary
    '''
    def getWord(self, word):
        return self.word_map.get(word, word) 

if __name__ == "__main__":
    print("RegEx replacers")
    replacer = RegexpReplacer()

    strExample1 = "can't is a contraction"
    print(strExample1)
    result = replacer.expand(strExample1)
    print(result)

    strExample2 = "I should've done that thing I didn't do"
    print(strExample2)
    result = replacer.expand(strExample2)
    print(result)

    print(strExample1)
    result = replacer.expandAndTokenize(strExample1)
    print(result)

    strExample3 = 'gooose'
    print(strExample3)
    result = replacer.removeRepeats(strExample3)
    print(result)

    strExample3 = 'looove'
    print(strExample3)
    result = replacer.removeRepeats(strExample3)
    print(result)

    replacer.createWordMap({'bday': 'birthday'})
    result = replacer.getWord('bday') 
    print(result)
    result = replacer.getWord('happy') 
    print(result)
